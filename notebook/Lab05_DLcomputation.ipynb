{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hufsaim/T10402201/blob/master/notebook/Lab05_DLcomputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e5d4ad38",
      "metadata": {
        "id": "e5d4ad38"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29f00679",
      "metadata": {
        "id": "29f00679",
        "outputId": "35f92488-ade2-4398-950d-038bdc3fad14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Apr 14 19:04:45 2022       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  GeForce RTX 3090    Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
            "| 36%   30C    P8    19W / 350W |  17155MiB / 24265MiB |      0%      Default |\r\n",
            "|                               |                      |                  N/A |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                  |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
            "|        ID   ID                                                   Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|    0   N/A  N/A      1383      G   /usr/lib/xorg/Xorg                 36MiB |\r\n",
            "|    0   N/A  N/A      7858      G   /usr/lib/xorg/Xorg                 89MiB |\r\n",
            "|    0   N/A  N/A    412943      C   ...da3/envs/torch/bin/python    17021MiB |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe45fe28",
      "metadata": {
        "id": "fe45fe28"
      },
      "source": [
        "## Tensor의 저장 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca739dd9",
      "metadata": {
        "id": "ca739dd9",
        "outputId": "9a47575d-86c2-4d48-e0df-227b97ec948c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 4, 8]), tensor([ 0,  3,  6,  9, 12]))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1,2,4,8])\n",
        "y = torch.tensor([0,3,6,9,12])\n",
        "x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62537719",
      "metadata": {
        "id": "62537719"
      },
      "outputs": [],
      "source": [
        "my_dict = {'d1':x, 'd2':y}\n",
        "torch.save(my_dict,'my_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a43286",
      "metadata": {
        "id": "a5a43286",
        "outputId": "2962f009-84cf-4948-e650-a54a2b4ebbdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d: {'d1': tensor([1, 2, 4, 8]), 'd2': tensor([ 0,  3,  6,  9, 12])}\n",
            "d['d2']: tensor([ 0,  3,  6,  9, 12])\n"
          ]
        }
      ],
      "source": [
        "d = torch.load('my_data')\n",
        "print(\"d:\",d)\n",
        "print(\"d['d2']:\",d['d2'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "303bff6c",
      "metadata": {
        "id": "303bff6c"
      },
      "source": [
        "## Network 파라미터 확인 및 직접 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db105bd",
      "metadata": {
        "id": "4db105bd",
        "outputId": "21481f6c-0119-444d-f838-97d7ed9cb407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=3, out_features=3, bias=False)\n",
              "  (1): Softmax(dim=None)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1 = nn.Sequential(nn.Linear(3,3,bias=False),nn.Softmax())\n",
        "net1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3986148e",
      "metadata": {
        "id": "3986148e",
        "outputId": "4f91926d-5afe-48f8-f503-f1768506bdb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1694,  0.0433, -0.4909],\n",
              "        [-0.5456,  0.0588,  0.2438],\n",
              "        [-0.0405,  0.2435,  0.0562]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1[0].weight.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de704624",
      "metadata": {
        "id": "de704624",
        "outputId": "0129d563-7329-4be3-ebf3-c41c285475e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight',\n",
              "              tensor([[-0.1694,  0.0433, -0.4909],\n",
              "                      [-0.5456,  0.0588,  0.2438],\n",
              "                      [-0.0405,  0.2435,  0.0562]]))])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf72d568",
      "metadata": {
        "id": "cf72d568"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([3.,3.,3.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3249272f",
      "metadata": {
        "id": "3249272f",
        "outputId": "58a65556-0ad6-43a6-b7e0-e39ca52a0cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0558, 0.1713, 0.7729])\n"
          ]
        }
      ],
      "source": [
        "y = torch.matmul(net1[0].weight.data,x).softmax(0)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ece6fb",
      "metadata": {
        "id": "b7ece6fb",
        "outputId": "290b4f8a-c156-46a5-86d2-22cc6fa05e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0558, 0.1713, 0.7729], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/miruware/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "y = net1(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0918d0e3",
      "metadata": {
        "id": "0918d0e3",
        "outputId": "1ba7f7eb-42a0-424c-bd7a-d79c47399842"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1[0].weight.data = torch.eye(3)\n",
        "net1[0].weight.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e11270",
      "metadata": {
        "id": "f5e11270",
        "outputId": "310a813d-484c-4b85-89ca-6f8cec9ccb3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.3333, 0.3333, 0.3333], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = net1(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc8484f",
      "metadata": {
        "id": "4bc8484f"
      },
      "source": [
        "## Network 파라미터들의 저장 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "470e68b1",
      "metadata": {
        "id": "470e68b1",
        "outputId": "ff0c242d-cb33-4fcb-ee9f-4b540022d9a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight',\n",
              "              tensor([[1., 0., 0.],\n",
              "                      [0., 1., 0.],\n",
              "                      [0., 0., 1.]]))])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bdba0df",
      "metadata": {
        "id": "8bdba0df"
      },
      "outputs": [],
      "source": [
        "torch.save(net1.state_dict(),'net1.params')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a231497",
      "metadata": {
        "id": "5a231497",
        "outputId": "cfa5c95a-0008-4906-cfce-d71b35f9dd9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight',\n",
              "              tensor([[ 0.4436,  0.4721, -0.4767],\n",
              "                      [ 0.5730, -0.1541,  0.1248],\n",
              "                      [-0.3381, -0.3861, -0.1668]]))])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net2 = nn.Sequential(nn.Linear(3,3,bias=False),nn.Softmax())\n",
        "net2.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31688a3a",
      "metadata": {
        "id": "31688a3a",
        "outputId": "ac952f52-798a-4aae-fed3-d14e3fa5b0c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.4189, 0.5734, 0.0077], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = net2(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6695bc5f",
      "metadata": {
        "id": "6695bc5f",
        "outputId": "c33052fb-94fa-432f-f656-3ce83d371d52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight',\n",
              "              tensor([[1., 0., 0.],\n",
              "                      [0., 1., 0.],\n",
              "                      [0., 0., 1.]]))])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1_params = torch.load('net1.params')\n",
        "net1_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b463e0",
      "metadata": {
        "id": "d7b463e0",
        "outputId": "64b4bd45-cf64-4067-f8f2-e34c2f34ee2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight',\n",
              "              tensor([[1., 0., 0.],\n",
              "                      [0., 1., 0.],\n",
              "                      [0., 0., 1.]]))])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net2.load_state_dict(net1_params)\n",
        "net2.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448355df",
      "metadata": {
        "id": "448355df",
        "outputId": "f1ad8a2a-a3b6-4454-f4b3-75ed45c4ec0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.3333, 0.3333, 0.3333], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = net2(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "315a56e3",
      "metadata": {
        "id": "315a56e3"
      },
      "source": [
        "## GPU활용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a71fff",
      "metadata": {
        "id": "d2a71fff",
        "outputId": "e4f86929-f321-4234-8b2d-78b88f6f5587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "활용가능 NVIDIA gpu 개수는? 1\n"
          ]
        }
      ],
      "source": [
        "print(\"활용가능 NVIDIA gpu 개수는?\",torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d7f610",
      "metadata": {
        "id": "84d7f610",
        "outputId": "5569811d-84bb-4c4d-9fbd-9c3f5f51076e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda:0\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(\"device:\",device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035298d1",
      "metadata": {
        "id": "035298d1",
        "outputId": "722eec7a-c27b-4457-b136-60bd85670852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(net1[0].weight.data.device)\n",
        "print(x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019f2223",
      "metadata": {
        "id": "019f2223",
        "outputId": "9aa7c63c-dc0f-4f72-abc3-3360e987cae6"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_505287/1177256202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)"
          ]
        }
      ],
      "source": [
        "x_gpu = x.to(device)\n",
        "net1(x_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c6ac9c",
      "metadata": {
        "id": "89c6ac9c",
        "outputId": "9f9ebfab-6638-4c24-bc77-ab3ed2a632e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.3333, 0.3333, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1.to(\"cuda:0\")\n",
        "net1(x_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c9417a",
      "metadata": {
        "id": "64c9417a",
        "outputId": "11b2761f-0796-4958-f7e7-0101e6cdbf04"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_505287/1345524742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)"
          ]
        }
      ],
      "source": [
        "net1(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c0b624",
      "metadata": {
        "id": "e5c0b624",
        "outputId": "a10c2469-4c7a-4a54-de0a-69bd582d3759"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.3333, 0.3333, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1(x.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e61da0",
      "metadata": {
        "id": "31e61da0"
      },
      "source": [
        "## GPU를 통한 deep network 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b837c9",
      "metadata": {
        "id": "57b837c9"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a6b62e",
      "metadata": {
        "id": "20a6b62e",
        "outputId": "e79f2154-94f2-48d6-d11b-a28e74ac4f3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "  (5): ReLU()\n",
              "  (6): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (7): ReLU()\n",
              "  (8): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (9): ReLU()\n",
              "  (10): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  (11): ReLU()\n",
              "  (12): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deepnet = nn.Sequential(nn.Linear(1024,1024),nn.ReLU(),\n",
        "                       nn.Linear(1024,2048),nn.ReLU(),\n",
        "                       nn.Linear(2048,4096),nn.ReLU(),\n",
        "                       nn.Linear(4096,4096),nn.ReLU(),\n",
        "                       nn.Linear(4096,2048),nn.ReLU(),\n",
        "                       nn.Linear(2048,1024),nn.ReLU(),\n",
        "                        nn.Linear(1024,2))\n",
        "deepnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120a2034",
      "metadata": {
        "id": "120a2034"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "alg = torch.optim.SGD(deepnet.parameters(),0.01, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fa95e5",
      "metadata": {
        "id": "e9fa95e5",
        "outputId": "926d173b-0daf-4bd9-88f2-7401dbac4877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculation time: 40.0 seconds\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 16\n",
        "s1 = time.time()\n",
        "deepnet.to(\"cpu\")\n",
        "for epoch in range(num_epochs):\n",
        "    X = torch.randn((4096,1024))\n",
        "    y = torch.randint(0,2,(4096,))\n",
        "    y_pred = deepnet(X)\n",
        "    l = loss(y_pred,y)\n",
        "    l.backward()\n",
        "    alg.step()\n",
        "    alg.zero_grad()\n",
        "s2 = time.time()\n",
        "\n",
        "print(f'calculation time: {np.round(s2-s1)} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa5112af",
      "metadata": {
        "id": "fa5112af",
        "outputId": "8434f0ee-356e-4925-956c-109c74df3f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e96b2e40",
      "metadata": {
        "id": "e96b2e40",
        "outputId": "dccf95e4-7a46-4925-8b96-90bc0c56c765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculation time: 1.0 seconds\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 16\n",
        "s1 = time.time()\n",
        "deepnet.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    X = torch.randn((4096,1024)).to(device)\n",
        "    y = torch.randint(0,2,(4096,)).to(\"cuda:0\")\n",
        "    y_pred = deepnet(X)\n",
        "    l = loss(y_pred,y)\n",
        "    l.backward()\n",
        "    alg.step()\n",
        "    alg.zero_grad()\n",
        "s2 = time.time()\n",
        "\n",
        "print(f'calculation time: {np.round(s2-s1)} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3438bf",
      "metadata": {
        "id": "5c3438bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2679434",
      "metadata": {
        "id": "e2679434"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}